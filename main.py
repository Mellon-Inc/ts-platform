import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import sys
import os
from typing import Dict, List, Union, Tuple, Any, Optional

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã¨å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from config import APP_TITLE, APP_DESCRIPTION, AVAILABLE_MODELS, DEFAULT_PARAMS, DEFAULT_FORECAST_PERIODS
from utils import (load_cached_data, show_success, show_error, show_info, show_warning,
                  create_downloadable_csv, detect_frequency, plot_time_series, plot_multiple_series)

# å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from modules.preprocess import clean_data, normalize_data, make_stationary, inverse_transform
from modules.features import (add_time_features, add_lag_features, add_rolling_features, 
                            detect_optimal_lags, get_feature_importance)

# ãƒšãƒ¼ã‚¸è¨­å®šã¨ã‚¿ã‚¤ãƒˆãƒ«
st.set_page_config(
    page_title=APP_TITLE,
    page_icon="ğŸ“ˆ",
    layout="wide"
)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
def init_session_state():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’åˆæœŸåŒ–"""
    if 'page' not in st.session_state:
        st.session_state.page = 'upload'
    if 'data' not in st.session_state:
        st.session_state.data = None
    if 'clean_data' not in st.session_state:
        st.session_state.clean_data = None
    if 'featured_data' not in st.session_state:
        st.session_state.featured_data = None
    if 'target_col' not in st.session_state:
        st.session_state.target_col = None
    if 'date_col' not in st.session_state:
        st.session_state.date_col = None
    if 'data_frequency' not in st.session_state:
        st.session_state.data_frequency = None
    if 'eda_results' not in st.session_state:
        st.session_state.eda_results = {}
    if 'selected_model' not in st.session_state:
        st.session_state.selected_model = None
    if 'model_params' not in st.session_state:
        st.session_state.model_params = {}
    if 'trained_model' not in st.session_state:
        st.session_state.trained_model = None
    if 'evaluation_results' not in st.session_state:
        st.session_state.evaluation_results = None
    if 'forecast' not in st.session_state:
        st.session_state.forecast = None
    if 'transform_info' not in st.session_state:
        st.session_state.transform_info = None
    if 'scalers' not in st.session_state:
        st.session_state.scalers = None

# ã‚¢ãƒ—ãƒªã®åˆæœŸåŒ–
init_session_state()

# ã‚¢ãƒ—ãƒªã®ã‚¿ã‚¤ãƒˆãƒ«
st.title(APP_TITLE)
st.markdown(APP_DESCRIPTION)

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
def navigation():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¡ãƒ‹ãƒ¥ãƒ¼"""
    st.sidebar.title("ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³")
    
    pages = {
        "ãƒ‡ãƒ¼ã‚¿ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰": "upload",
        "ãƒ‡ãƒ¼ã‚¿ã®æ¢ç´¢çš„åˆ†æ": "eda",
        "ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°": "training",
        "äºˆæ¸¬ã®ç”Ÿæˆ": "forecast"
    }
    
    # ç¾åœ¨ã®ãƒšãƒ¼ã‚¸ã‚’ç‰¹å®š
    current_page_name = [name for name, code in pages.items() if code == st.session_state.page][0]
    
    # ãƒšãƒ¼ã‚¸é¸æŠãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³
    selected_page = st.sidebar.radio("ãƒšãƒ¼ã‚¸ã‚’é¸æŠ", list(pages.keys()), index=list(pages.keys()).index(current_page_name))
    
    # é¸æŠã•ã‚ŒãŸãƒšãƒ¼ã‚¸ã«å¿œã˜ã¦çŠ¶æ…‹ã‚’æ›´æ–°
    if pages[selected_page] != st.session_state.page:
        if pages[selected_page] == 'upload':
            st.session_state.page = 'upload'
            st.rerun()
        elif pages[selected_page] == 'eda':
            if st.session_state.data is not None:
                st.session_state.page = 'eda'
                st.rerun()
            else:
                st.sidebar.error("å…ˆã«ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
        elif pages[selected_page] == 'training':
            if st.session_state.data is not None:
                st.session_state.page = 'training'
                st.rerun()
            else:
                st.sidebar.error("å…ˆã«ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
        elif pages[selected_page] == 'forecast':
            if st.session_state.trained_model is not None:
                st.session_state.page = 'forecast'
                st.rerun()
            else:
                st.sidebar.error("å…ˆã«ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ãã ã•ã„")

# ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒšãƒ¼ã‚¸
def show_upload_page():
    """ãƒ‡ãƒ¼ã‚¿ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨å‰å‡¦ç†ã‚’è¡Œã†ãƒšãƒ¼ã‚¸"""
    st.header("ãƒ‡ãƒ¼ã‚¿ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    
    uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=['csv'])
    
    if uploaded_file is not None:
        try:
            # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
            df = load_cached_data(uploaded_file)
            
            if df is not None:
                st.success("ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£å¸¸ã«èª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸ")
                
                # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                st.subheader("ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
                st.dataframe(df.head())
                
                # åˆ—ã®æ¦‚è¦
                st.subheader("åˆ—ã®æƒ…å ±")
                col_info = pd.DataFrame({
                    'åˆ—å': df.columns,
                    'ãƒ‡ãƒ¼ã‚¿å‹': df.dtypes,
                    'éæ¬ æå€¤æ•°': df.count().values,
                    'æ¬ æå€¤æ•°': df.isna().sum().values,
                    'æ¬ æç‡ (%)': df.isna().sum().values / len(df) * 100
                })
                st.dataframe(col_info)
                
                # å¤‰æ•°ã®é¸æŠ
                st.subheader("å¤‰æ•°ã®é¸æŠ")
                
                # æ—¥ä»˜ã‚«ãƒ©ãƒ ã®å€™è£œã‚’çµã‚Šè¾¼ã‚€ï¼ˆ'date'ã‚„'time'ã‚’å«ã‚€åˆ—åã‚’å„ªå…ˆï¼‰
                date_col_candidates = [col for col in df.columns if any(keyword in col.lower() for keyword in ['date', 'time', 'day', 'year', 'month'])]
                if not date_col_candidates:
                    date_col_candidates = df.columns.tolist()
                
                # æœ€ã‚‚å¯èƒ½æ€§ã®é«˜ã„æ—¥ä»˜ã‚«ãƒ©ãƒ ã‚’åˆæœŸé¸æŠ
                default_date_index = 0
                for i, col in enumerate(date_col_candidates):
                    if 'date' in col.lower():
                        default_date_index = i
                        break
                
                date_col = st.selectbox("æ—¥ä»˜å¤‰æ•°ã‚’é¸æŠ", date_col_candidates, index=default_date_index)
                
                # æ•°å€¤ã‚«ãƒ©ãƒ ã®ã¿ã‚’æŠ½å‡º
                numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()
                
                # ç›®æ¨™å¤‰æ•°ï¼ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼‰ã®é¸æŠ
                target_col = st.selectbox("äºˆæ¸¬å¯¾è±¡ã®å¤‰æ•°ã‚’é¸æŠ", numeric_cols)
                
                # å‰å‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³
                st.subheader("å‰å‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    handle_missing = st.checkbox("æ¬ æå€¤ã‚’å‡¦ç†ã™ã‚‹", value=True)
                    handle_outliers = st.checkbox("å¤–ã‚Œå€¤ã‚’å‡¦ç†ã™ã‚‹", value=False)
                
                with col2:
                    normalize = st.checkbox("ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–ã™ã‚‹", value=False)
                    make_data_stationary = st.checkbox("ãƒ‡ãƒ¼ã‚¿ã‚’å®šå¸¸åŒ–ã™ã‚‹", value=False)
                    
                if make_data_stationary:
                    stationary_method = st.selectbox(
                        "å®šå¸¸åŒ–ã®æ–¹æ³•", 
                        ["å·®åˆ† (Difference)", "å¯¾æ•°å¤‰æ› (Log)", "å¤‰åŒ–ç‡ (Percent Change)"],
                        index=0
                    )
                    method_map = {
                        "å·®åˆ† (Difference)": "diff",
                        "å¯¾æ•°å¤‰æ› (Log)": "log",
                        "å¤‰åŒ–ç‡ (Percent Change)": "pct_change"
                    }
                
                # å‰å‡¦ç†ã‚’é©ç”¨ã™ã‚‹ãƒœã‚¿ãƒ³
                if st.button("å‰å‡¦ç†ã‚’é©ç”¨"):
                    with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’å‰å‡¦ç†ä¸­..."):
                        # æ—¥ä»˜å‹ã«å¤‰æ›
                        try:
                            df[date_col] = pd.to_datetime(df[date_col])
                        except Exception as e:
                            st.error(f"æ—¥ä»˜åˆ—ã®å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                            st.stop()
                        
                        # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
                        clean_df = clean_data(df, date_col, target_col, handle_missing, handle_outliers)
                        
                        # ãƒ‡ãƒ¼ã‚¿ã®é »åº¦ã‚’æ¤œå‡º
                        data_frequency = detect_frequency(clean_df[date_col])
                        
                        # æ­£è¦åŒ–
                        transform_info = None
                        scalers = None
                        
                        if normalize:
                            normalized_df, scalers = normalize_data(
                                clean_df, 
                                target_col, 
                                exclude_cols=[date_col], 
                                method='minmax'
                            )
                            clean_df = normalized_df
                        
                        # å®šå¸¸åŒ–
                        if make_data_stationary:
                            method = method_map[stationary_method]
                            stationary_df, transform_info = make_stationary(
                                clean_df, 
                                target_col, 
                                method=method, 
                                diff_order=1 if method == 'diff' else None
                            )
                            clean_df = stationary_df
                        
                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°
                        st.session_state.data = df.copy()
                        st.session_state.clean_data = clean_df.copy()
                        st.session_state.target_col = target_col
                        st.session_state.date_col = date_col
                        st.session_state.data_frequency = data_frequency
                        st.session_state.transform_info = transform_info
                        st.session_state.scalers = scalers
                    
                    # æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                    show_success("å‰å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                    st.subheader("å‰å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
                    st.dataframe(clean_df.head())
                    
                    # å‡¦ç†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã«
                    create_downloadable_csv(clean_df, "preprocessed_data.csv")
                    
                    # åŸºæœ¬çš„ãªæ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆ
                    st.subheader("æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆ")
                    fig = px.line(
                        clean_df, 
                        x=date_col, 
                        y=target_col, 
                        title=f"{target_col} vs æ™‚é–“"
                    )
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # EDAãƒšãƒ¼ã‚¸ã«é€²ã‚€ãƒœã‚¿ãƒ³
                    if st.button("ãƒ‡ãƒ¼ã‚¿åˆ†æã«é€²ã‚€"):
                        # ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ã‹ã‚‰é·ç§»
                        if st.session_state.data is not None and st.session_state.clean_data is not None:
                            st.session_state.page = 'eda'
                            # æ˜ç¤ºçš„ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ä¿å­˜ã—ã¦å†èª­ã¿è¾¼ã¿
                            st.experimental_rerun()
                        else:
                            st.error("ãƒ‡ãƒ¼ã‚¿ãŒæ­£ã—ãå‡¦ç†ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€EDAãƒšãƒ¼ã‚¸ã«é€²ã‚ã¾ã›ã‚“ã€‚")
        
        except Exception as e:
            show_error(f"ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

# EDA (æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿åˆ†æ) ãƒšãƒ¼ã‚¸
def show_eda_page():
    """æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿åˆ†æã‚’è¡Œã†ãƒšãƒ¼ã‚¸"""
    st.header("ãƒ‡ãƒ¼ã‚¿ã®æ¢ç´¢çš„åˆ†æ")
    
    # ãƒ‡ãƒ¼ã‚¿ã¨åˆ—ã®ç¢ºèª
    if st.session_state.clean_data is None:
        show_error("å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…ˆã«ãƒ‡ãƒ¼ã‚¿ã‚’å‰å‡¦ç†ã—ã¦ãã ã•ã„ã€‚")
        return
    
    df = st.session_state.clean_data
    target_col = st.session_state.target_col
    date_col = st.session_state.date_col
    
    # EDAã®ã‚¿ãƒ–
    tabs = st.tabs(["æ™‚ç³»åˆ—ç‰¹æ€§", "åˆ†å¸ƒã¨çµ±è¨ˆé‡", "ç›¸é–¢åˆ†æ", "ç‰¹å¾´é‡ç”Ÿæˆ"])
    
    # ã‚¿ãƒ–1: æ™‚ç³»åˆ—ç‰¹æ€§
    with tabs[0]:
        st.subheader("æ™‚ç³»åˆ—ç‰¹æ€§ã®åˆ†æ")
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰ã€å­£ç¯€æ€§ã€å®šå¸¸æ€§ã®åˆ†æ
        col1, col2 = st.columns(2)
        
        with col1:
            # åŸºæœ¬çš„ãªæ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆ
            st.subheader("æ™‚é–“ã«å¯¾ã™ã‚‹ç›®æ¨™å¤‰æ•°")
            plot_time_series(df, date_col, target_col)
            
            # ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡º
            from scipy import stats
            
            # ç·šå½¢å›å¸°ã§ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡º
            x = np.array(range(len(df)))
            y = df[target_col].values
            
            slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)
            
            # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’è¿½åŠ 
            trend_line = intercept + slope * x
            
            fig = px.scatter(
                df, 
                x=date_col, 
                y=target_col, 
                opacity=0.7,
                title=f"{target_col}ã®ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ"
            )
            
            fig.add_scatter(
                x=df[date_col], 
                y=trend_line, 
                mode='lines', 
                name='ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³',
                line=dict(color='red', width=2)
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # ãƒˆãƒ¬ãƒ³ãƒ‰ã®æœ‰æ„æ€§
            has_trend = p_value < 0.05 and abs(r_value) > 0.3
            
            if has_trend:
                trend_dir = "ä¸Šæ˜‡" if slope > 0 else "ä¸‹é™"
                st.info(f"æœ‰æ„ãª{trend_dir}ãƒˆãƒ¬ãƒ³ãƒ‰ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ (p-value: {p_value:.4f}, rÂ²: {r_value**2:.4f})")
            else:
                st.info(f"æœ‰æ„ãªãƒˆãƒ¬ãƒ³ãƒ‰ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ (p-value: {p_value:.4f}, rÂ²: {r_value**2:.4f})")
        
        with col2:
            # å­£ç¯€æ€§åˆ†æ
            st.subheader("å­£ç¯€æ€§åˆ†æ")
            
            # ãƒ‡ãƒ¼ã‚¿ã®é »åº¦ã«åŸºã¥ã„ã¦é©åˆ‡ãªåˆ†è§£æ–¹æ³•ã‚’é¸æŠ
            import statsmodels.api as sm
            from statsmodels.tsa.seasonal import seasonal_decompose
            
            try:
                # æ¬ æå€¤ãŒå«ã¾ã‚Œã‚‹ã¨ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ãŸã‚ã€è£œé–“
                temp_df = df.copy()
                temp_df[target_col] = temp_df[target_col].interpolate()
                
                # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ—¥ä»˜ã«è¨­å®š
                temp_df = temp_df.set_index(date_col)
                
                # å­£ç¯€åˆ†è§£
                freq_map = {
                    'hourly': 24,
                    'daily': 7,
                    'weekly': 52,
                    'monthly': 12,
                    'quarterly': 4,
                    'yearly': 1
                }
                
                freq = st.session_state.data_frequency
                period = freq_map.get(freq, 12)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯12
                
                decomposition = seasonal_decompose(
                    temp_df[target_col], 
                    model='additive', 
                    period=period,
                    extrapolate_trend='freq'
                )
                
                # åˆ†è§£çµæœã®ãƒ—ãƒ­ãƒƒãƒˆ
                trend = decomposition.trend
                seasonal = decomposition.seasonal
                residual = decomposition.resid
                
                # å­£ç¯€æ€§æˆåˆ†ã®å¼·ã•ã‚’è©•ä¾¡
                seasonal_strength = abs(seasonal).mean() / (abs(trend).mean() + abs(seasonal).mean() + abs(residual).mean())
                has_seasonality = seasonal_strength > 0.1
                
                # å„æˆåˆ†ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«æ ¼ç´
                decomp_df = pd.DataFrame({
                    'trend': trend,
                    'seasonal': seasonal,
                    'residual': residual
                })
                
                # å„æˆåˆ†ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
                for component in ['trend', 'seasonal', 'residual']:
                    fig = px.line(
                        decomp_df, 
                        y=component,
                        title=f"{component.capitalize()} æˆåˆ†"
                    )
                    st.plotly_chart(fig, use_container_width=True)
                
                if has_seasonality:
                    st.info(f"å­£ç¯€æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ (å­£ç¯€æ€§å¼·åº¦: {seasonal_strength:.4f})")
                else:
                    st.info(f"é¡•è‘—ãªå­£ç¯€æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ (å­£ç¯€æ€§å¼·åº¦: {seasonal_strength:.4f})")
                
                # å®šå¸¸æ€§æ¤œå®š
                from statsmodels.tsa.stattools import adfuller
                
                # ADFæ¤œå®šã‚’å®Ÿè¡Œ
                result = adfuller(df[target_col].dropna())
                
                adf_stat = result[0]
                p_value = result[1]
                critical_values = result[4]
                
                is_stationary = p_value < 0.05
                
                st.subheader("å®šå¸¸æ€§æ¤œå®š (ADF)")
                st.write(f"ADFçµ±è¨ˆé‡: {adf_stat:.4f}")
                st.write(f"på€¤: {p_value:.4f}")
                st.write("è‡¨ç•Œå€¤:")
                for key, value in critical_values.items():
                    st.write(f"   {key}: {value:.4f}")
                
                if is_stationary:
                    st.success("æ™‚ç³»åˆ—ã¯å®šå¸¸çš„ã§ã™ (p < 0.05)")
                else:
                    st.warning("æ™‚ç³»åˆ—ã¯éå®šå¸¸ã§ã™ (p >= 0.05)")
                
                # EDAçµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
                st.session_state.eda_results = {
                    'has_trend': has_trend,
                    'trend_direction': 'increasing' if slope > 0 else 'decreasing' if slope < 0 else 'none',
                    'trend_strength': abs(r_value),
                    'has_seasonality': has_seasonality,
                    'seasonality_strength': seasonal_strength,
                    'is_stationary': is_stationary,
                    'optimal_period': period
                }
                
            except Exception as e:
                st.error(f"å­£ç¯€æ€§åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    
    # ã‚¿ãƒ–2: åˆ†å¸ƒã¨çµ±è¨ˆé‡
    with tabs[1]:
        st.subheader("ãƒ‡ãƒ¼ã‚¿ã®åˆ†å¸ƒã¨çµ±è¨ˆé‡")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
            fig = px.histogram(
                df, 
                x=target_col, 
                nbins=30,
                title=f"{target_col}ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ "
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # ç®±ã²ã’å›³
            fig = px.box(
                df, 
                y=target_col,
                title=f"{target_col}ã®ç®±ã²ã’å›³"
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # QQãƒ—ãƒ­ãƒƒãƒˆ
            from scipy import stats
            
            # æ­£è¦åˆ†å¸ƒã«å¯¾ã™ã‚‹QQãƒ—ãƒ­ãƒƒãƒˆ
            quantiles = stats.probplot(df[target_col].dropna(), dist='norm')
            
            fig = go.Figure()
            fig.add_scatter(
                x=quantiles[0][0], 
                y=quantiles[0][1],
                mode='markers',
                name='ãƒ‡ãƒ¼ã‚¿ç‚¹'
            )
            
            # ç†è«–ç·šã‚’è¿½åŠ 
            fig.add_scatter(
                x=quantiles[0][0],
                y=quantiles[0][0] * quantiles[1][0] + quantiles[1][1],
                mode='lines',
                name='ç†è«–ç·š',
                line=dict(color='red')
            )
            
            fig.update_layout(
                title="æ­£è¦Q-Qãƒ—ãƒ­ãƒƒãƒˆ",
                xaxis_title="ç†è«–ä¸Šã®åˆ†ä½æ•°",
                yaxis_title="å®Ÿéš›ã®åˆ†ä½æ•°"
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # åŸºæœ¬çµ±è¨ˆé‡
            st.subheader("åŸºæœ¬çµ±è¨ˆé‡")
            
            stats_df = pd.DataFrame({
                'çµ±è¨ˆé‡': [
                    'ä»¶æ•°', 'æ¬ æå€¤', 'å¹³å‡', 'æ¨™æº–åå·®', 'æœ€å°å€¤', '25%åˆ†ä½', 
                    'ä¸­å¤®å€¤', '75%åˆ†ä½', 'æœ€å¤§å€¤', 'æ­ªåº¦', 'å°–åº¦'
                ],
                'å€¤': [
                    df[target_col].count(),
                    df[target_col].isna().sum(),
                    df[target_col].mean(),
                    df[target_col].std(),
                    df[target_col].min(),
                    df[target_col].quantile(0.25),
                    df[target_col].median(),
                    df[target_col].quantile(0.75),
                    df[target_col].max(),
                    df[target_col].skew(),
                    df[target_col].kurtosis()
                ]
            })
            
            st.dataframe(stats_df, use_container_width=True)
    
    # ã‚¿ãƒ–3: ç›¸é–¢åˆ†æ
    with tabs[2]:
        st.subheader("è‡ªå·±ç›¸é–¢åˆ†æ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # ACF (è‡ªå·±ç›¸é–¢é–¢æ•°)
            from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
            import matplotlib.pyplot as plt
            
            fig, ax = plt.subplots(figsize=(10, 6))
            
            try:
                plot_acf(df[target_col].dropna(), ax=ax, lags=30)
                ax.set_title('è‡ªå·±ç›¸é–¢é–¢æ•° (ACF)')
                st.pyplot(fig)
            except Exception as e:
                st.error(f"ACFã®è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        
        with col2:
            # PACF (åè‡ªå·±ç›¸é–¢é–¢æ•°)
            fig, ax = plt.subplots(figsize=(10, 6))
            
            try:
                plot_pacf(df[target_col].dropna(), ax=ax, lags=30)
                ax.set_title('åè‡ªå·±ç›¸é–¢é–¢æ•° (PACF)')
                st.pyplot(fig)
            except Exception as e:
                st.error(f"PACFã®è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        
        # æœ€é©ãƒ©ã‚°ã®æ¤œå‡º
        st.subheader("ARIMAãƒ¢ãƒ‡ãƒ«ã®æœ€é©ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¨å®š")
        
        try:
            # ACFã¨PACFã«åŸºã¥ã„ã¦æœ€é©ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¨å®š
            p, q = detect_optimal_lags(df, target_col)
            
            st.info(f"æ¨å®šã•ã‚ŒãŸARIMAãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: p={p}, q={q}")
            st.session_state.eda_results['optimal_p'] = p
            st.session_state.eda_results['optimal_q'] = q
            
            # ã“ã‚Œã‚’ARIMAãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã—ã¦è¨­å®š
            DEFAULT_PARAMS['ARIMA'] = {'p': p, 'd': 1 if not st.session_state.eda_results.get('is_stationary', False) else 0, 'q': q}
            DEFAULT_PARAMS['SARIMA']['p'] = p
            DEFAULT_PARAMS['SARIMA']['q'] = q
            
        except Exception as e:
            st.error(f"æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¨å®šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    
    # ã‚¿ãƒ–4: ç‰¹å¾´é‡ç”Ÿæˆ
    with tabs[3]:
        st.subheader("ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°")
        
        # ç‰¹å¾´é‡ç”Ÿæˆã‚ªãƒ—ã‚·ãƒ§ãƒ³
        add_time_features_option = st.checkbox("æ™‚é–“ãƒ™ãƒ¼ã‚¹ã®ç‰¹å¾´é‡ã‚’è¿½åŠ ", value=True)
        add_lag_features_option = st.checkbox("ãƒ©ã‚°ç‰¹å¾´é‡ã‚’è¿½åŠ ", value=True)
        add_rolling_features_option = st.checkbox("ç§»å‹•å¹³å‡ç‰¹å¾´é‡ã‚’è¿½åŠ ", value=True)
        
        # ã‚«ã‚¹ã‚¿ãƒ ãƒ©ã‚°æœŸé–“
        custom_lags = None
        if add_lag_features_option:
            use_custom_lags = st.checkbox("ã‚«ã‚¹ã‚¿ãƒ ãƒ©ã‚°ã‚’æŒ‡å®š", value=False)
            if use_custom_lags:
                custom_lags_input = st.text_input("ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®ãƒ©ã‚°æœŸé–“", "1,2,3,7")
                try:
                    custom_lags = [int(x.strip()) for x in custom_lags_input.split(",")]
                except ValueError:
                    st.error("æœ‰åŠ¹ãªæ•´æ•°ã®ãƒªã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        
        # ã‚«ã‚¹ã‚¿ãƒ ç§»å‹•å¹³å‡çª“ã‚µã‚¤ã‚º
        custom_windows = None
        if add_rolling_features_option:
            use_custom_windows = st.checkbox("ã‚«ã‚¹ã‚¿ãƒ ç§»å‹•å¹³å‡çª“ã‚µã‚¤ã‚ºã‚’æŒ‡å®š", value=False)
            if use_custom_windows:
                custom_windows_input = st.text_input("ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®çª“ã‚µã‚¤ã‚º", "3,7,14,30")
                try:
                    custom_windows = [int(x.strip()) for x in custom_windows_input.split(",")]
                except ValueError:
                    st.error("æœ‰åŠ¹ãªæ•´æ•°ã®ãƒªã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        
        # ç‰¹å¾´é‡ç”Ÿæˆãƒœã‚¿ãƒ³
        if st.button("ç‰¹å¾´é‡ã‚’ç”Ÿæˆ"):
            with st.spinner("ç‰¹å¾´é‡ã‚’ç”Ÿæˆä¸­..."):
                featured_df = df.copy()
                
                # æ™‚é–“ãƒ™ãƒ¼ã‚¹ã®ç‰¹å¾´é‡ã‚’è¿½åŠ 
                if add_time_features_option:
                    featured_df = add_time_features(featured_df, date_col)
                
                # ãƒ©ã‚°ç‰¹å¾´é‡ã‚’è¿½åŠ 
                if add_lag_features_option:
                    featured_df = add_lag_features(featured_df, target_col, lag_periods=custom_lags)
                
                # ç§»å‹•å¹³å‡ç‰¹å¾´é‡ã‚’è¿½åŠ 
                if add_rolling_features_option:
                    featured_df = add_rolling_features(featured_df, target_col, windows=custom_windows)
                
                # ç‰¹å¾´é‡ã‚’æ›´æ–°
                st.session_state.featured_data = featured_df
            
            # æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
            show_success("ç‰¹å¾´é‡ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸï¼")
            st.subheader("ç”Ÿæˆã•ã‚ŒãŸç‰¹å¾´é‡ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
            st.dataframe(featured_df.head())
            
            # ç‰¹å¾´é‡ã®é‡è¦åº¦ã‚’è¨ˆç®—ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã‚’ä½¿ç”¨ï¼‰
            try:
                # æ•°å€¤åˆ—ã®ã¿æŠ½å‡ºã—ã€target_colã¨date_colã‚’é™¤å¤–
                feature_cols = [col for col in featured_df.select_dtypes(include=['float64', 'int64']).columns 
                                if col != target_col and col != date_col]
                
                if len(feature_cols) > 0:
                    importance_df = get_feature_importance(
                        featured_df.dropna(), 
                        target_col, 
                        feature_cols
                    )
                    
                    st.subheader("ç‰¹å¾´é‡ã®é‡è¦åº¦")
                    
                    # ãƒˆãƒƒãƒ—15ã®ç‰¹å¾´é‡ã ã‘è¡¨ç¤º
                    top_features = importance_df.head(15)
                    
                    fig = px.bar(
                        top_features,
                        x='importance',
                        y='feature',
                        orientation='h',
                        title="ç‰¹å¾´é‡ã®é‡è¦åº¦ (ãƒˆãƒƒãƒ—15)",
                    )
                    fig.update_layout(yaxis={'categoryorder': 'total ascending'})
                    
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã«ã™ã‚‹
                    create_downloadable_csv(featured_df, "featured_data.csv")
            except Exception as e:
                st.error(f"ç‰¹å¾´é‡é‡è¦åº¦ã®è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

# ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒšãƒ¼ã‚¸
def show_training_page():
    """ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã†ãƒšãƒ¼ã‚¸"""
    st.header("ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°")
    
    # ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
    if st.session_state.clean_data is None:
        show_error("å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…ˆã«ãƒ‡ãƒ¼ã‚¿ã‚’å‰å‡¦ç†ã—ã¦ãã ã•ã„ã€‚")
        return
    
    # é€šå¸¸ã®å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‹ã€ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
    if st.session_state.featured_data is not None and st.button("ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨"):
        df = st.session_state.featured_data
        st.success("ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™")
    else:
        df = st.session_state.clean_data
    
    target_col = st.session_state.target_col
    date_col = st.session_state.date_col
    
    # ãƒ¢ãƒ‡ãƒ«é¸æŠã¨è¨­å®šã®ã‚¿ãƒ–
    tabs = st.tabs(["ãƒ¢ãƒ‡ãƒ«é¸æŠ", "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°", "è©•ä¾¡"])
    
    # ã‚¿ãƒ–1: ãƒ¢ãƒ‡ãƒ«é¸æŠ
    with tabs[0]:
        st.subheader("ãƒ¢ãƒ‡ãƒ«ã®é¸æŠ")
        
        # EDAçµæœã«åŸºã¥ã„ã¦æœ€é©ãªãƒ¢ãƒ‡ãƒ«ã‚’æ¨å¥¨
        eda_results = st.session_state.eda_results
        
        recommended_model = None
        if eda_results:
            has_trend = eda_results.get('has_trend', False)
            has_seasonality = eda_results.get('has_seasonality', False)
            is_stationary = eda_results.get('is_stationary', False)
            
            if has_seasonality:
                recommended_model = 'SARIMA'
            elif has_trend and not is_stationary:
                recommended_model = 'Prophet'
            elif is_stationary:
                recommended_model = 'ARIMA'
            else:
                recommended_model = 'Random Forest'
        
        # ãƒ¢ãƒ‡ãƒ«é¸æŠ
        model_options = list(AVAILABLE_MODELS.keys())
        default_index = model_options.index(recommended_model) if recommended_model in model_options else 0
        
        selected_model = st.selectbox(
            "äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ", 
            model_options,
            index=default_index,
            format_func=lambda x: AVAILABLE_MODELS[x]
        )
        
        if recommended_model:
            st.info(f"EDAçµæœã«åŸºã¥ãæ¨å¥¨ãƒ¢ãƒ‡ãƒ«: {AVAILABLE_MODELS[recommended_model]}")
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®š
        st.subheader("ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
        
        model_params = DEFAULT_PARAMS.get(selected_model, {}).copy()
        
        if selected_model == 'ARIMA':
            col1, col2, col3 = st.columns(3)
            with col1:
                model_params['p'] = st.number_input("ARæ¬¡æ•° (p)", min_value=0, max_value=10, value=model_params.get('p', 1))
            with col2:
                model_params['d'] = st.number_input("å·®åˆ†æ¬¡æ•° (d)", min_value=0, max_value=2, value=model_params.get('d', 1))
            with col3:
                model_params['q'] = st.number_input("MAæ¬¡æ•° (q)", min_value=0, max_value=10, value=model_params.get('q', 1))
        
        elif selected_model == 'SARIMA':
            col1, col2, col3 = st.columns(3)
            with col1:
                model_params['p'] = st.number_input("ARæ¬¡æ•° (p)", min_value=0, max_value=5, value=model_params.get('p', 1))
                model_params['P'] = st.number_input("å­£ç¯€ARæ¬¡æ•° (P)", min_value=0, max_value=5, value=model_params.get('P', 1))
            with col2:
                model_params['d'] = st.number_input("å·®åˆ†æ¬¡æ•° (d)", min_value=0, max_value=2, value=model_params.get('d', 1))
                model_params['D'] = st.number_input("å­£ç¯€å·®åˆ†æ¬¡æ•° (D)", min_value=0, max_value=1, value=model_params.get('D', 0))
            with col3:
                model_params['q'] = st.number_input("MAæ¬¡æ•° (q)", min_value=0, max_value=5, value=model_params.get('q', 1))
                model_params['Q'] = st.number_input("å­£ç¯€MAæ¬¡æ•° (Q)", min_value=0, max_value=5, value=model_params.get('Q', 1))
            
            model_params['m'] = st.number_input(
                "å­£ç¯€å‘¨æœŸ (m)", 
                min_value=2, 
                max_value=365, 
                value=model_params.get('m', eda_results.get('optimal_period', 12))
            )
        
        elif selected_model == 'Prophet':
            col1, col2 = st.columns(2)
            with col1:
                yearly_options = ['auto', True, False]
                yearly_index = yearly_options.index(model_params.get('yearly_seasonality', 'auto'))
                model_params['yearly_seasonality'] = st.selectbox(
                    "å¹´æ¬¡å­£ç¯€æ€§", 
                    yearly_options, 
                    index=yearly_index
                )
                
                daily_options = ['auto', True, False]
                daily_index = daily_options.index(model_params.get('daily_seasonality', 'auto'))
                model_params['daily_seasonality'] = st.selectbox(
                    "æ—¥æ¬¡å­£ç¯€æ€§", 
                    daily_options, 
                    index=daily_index
                )
            
            with col2:
                weekly_options = ['auto', True, False]
                weekly_index = weekly_options.index(model_params.get('weekly_seasonality', 'auto'))
                model_params['weekly_seasonality'] = st.selectbox(
                    "é€±æ¬¡å­£ç¯€æ€§", 
                    weekly_options, 
                    index=weekly_index
                )
                
                model_params['seasonality_mode'] = st.selectbox(
                    "å­£ç¯€æ€§ãƒ¢ãƒ¼ãƒ‰", 
                    ['additive', 'multiplicative'], 
                    index=0
                )
        
        elif selected_model == 'Random Forest':
            col1, col2 = st.columns(2)
            with col1:
                model_params['n_estimators'] = st.slider(
                    "æœ¨ã®æ•°", 
                    min_value=10, 
                    max_value=500, 
                    value=model_params.get('n_estimators', 100),
                    step=10
                )
            
            with col2:
                model_params['max_depth'] = st.slider(
                    "æœ€å¤§æ·±ã•", 
                    min_value=1, 
                    max_value=30, 
                    value=model_params.get('max_depth', 10)
                )
        
        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®š
        st.subheader("ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®š")
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿åˆ†å‰²
        test_size = st.slider("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å‰²åˆ", min_value=0.1, max_value=0.5, value=0.2, step=0.05)
        
        # ãƒ¢ãƒ‡ãƒ«é¸æŠã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
        if st.button("ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®šã‚’ä¿å­˜"):
            st.session_state.selected_model = selected_model
            st.session_state.model_params = model_params
            st.session_state.test_size = test_size
            show_success("ãƒ¢ãƒ‡ãƒ«è¨­å®šãŒä¿å­˜ã•ã‚Œã¾ã—ãŸï¼ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¿ãƒ–ã«é€²ã‚“ã§ãã ã•ã„ã€‚")

        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®å®Ÿè¡Œ
        if st.button("ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°"):
            if st.session_state.selected_model is None:
                show_error("ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’å…ˆã«ä¿å­˜ã—ã¦ãã ã•ã„")
            else:
                with st.spinner("ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­..."):
                    # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
                    df = st.session_state.featured_data if st.session_state.featured_data is not None else st.session_state.clean_data
                    target_col = st.session_state.target_col
                    date_col = st.session_state.date_col
                    model_type = st.session_state.selected_model
                    params = st.session_state.model_params
                    
                    # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ
                    trained_model = train_model(df, target_col, date_col, model_type, params, test_size)
                    
                    if trained_model is not None:
                        st.session_state.trained_model = trained_model
                        
                        # è©•ä¾¡å®Ÿè¡Œ
                        evaluation_results = evaluate_model(
                            trained_model, 
                            df, 
                            target_col, 
                            date_col, 
                            model_type
                        )
                        
                        st.session_state.evaluation_results = evaluation_results
                        
                        show_success("ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                        
                        # è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¡¨ç¤º
                        st.subheader("ãƒ¢ãƒ‡ãƒ«è©•ä¾¡")
                        metrics_df = pd.DataFrame({
                            'ãƒ¡ãƒˆãƒªã‚¯ã‚¹': ['RMSE', 'MAE', 'MAPE (%)', 'RÂ²'],
                            'å€¤': [
                                evaluation_results['rmse'],
                                evaluation_results['mae'],
                                evaluation_results['mape'],
                                evaluation_results['r2']
                            ]
                        })
                        st.dataframe(metrics_df)
                        
                        # ãƒ—ãƒ­ãƒƒãƒˆã®è¡¨ç¤º
                        plot_evaluation(evaluation_results)
                        
                        if st.button("äºˆæ¸¬ãƒšãƒ¼ã‚¸ã«é€²ã‚€"):
                            st.session_state.page = 'forecast'
                            st.rerun()

def show_forecast_page():
    """å°†æ¥äºˆæ¸¬ã‚’ç”Ÿæˆã™ã‚‹ãƒšãƒ¼ã‚¸"""
    st.header("äºˆæ¸¬ã®ç”Ÿæˆ")
    
    if st.session_state.trained_model is None:
        show_error("å…ˆã«ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ãã ã•ã„")
        return
    
    # äºˆæ¸¬æœŸé–“ã®è¨­å®š
    st.subheader("äºˆæ¸¬æœŸé–“ã®è¨­å®š")
    
    freq = st.session_state.data_frequency
    default_periods = DEFAULT_FORECAST_PERIODS.get(freq, 12)
    
    forecast_periods = st.number_input(
        "äºˆæ¸¬ã™ã‚‹æœŸé–“æ•°", 
        min_value=1, 
        max_value=1000, 
        value=default_periods
    )
    
    # ä¿¡é ¼åŒºé–“ã®è¨­å®š
    confidence_level = st.slider(
        "ä¿¡é ¼åŒºé–“ (%)", 
        min_value=50, 
        max_value=99, 
        value=95, 
        step=5
    ) / 100
    
    # äºˆæ¸¬å®Ÿè¡Œ
    if st.button("äºˆæ¸¬ã‚’ç”Ÿæˆ"):
        with st.spinner("äºˆæ¸¬ã‚’ç”Ÿæˆä¸­..."):
            model = st.session_state.trained_model
            df = st.session_state.featured_data if st.session_state.featured_data is not None else st.session_state.clean_data
            target_col = st.session_state.target_col
            date_col = st.session_state.date_col
            model_type = st.session_state.selected_model
            
            forecast_results = generate_forecast(
                model, 
                df, 
                target_col, 
                date_col, 
                model_type, 
                forecast_periods, 
                confidence_level
            )
            
            if forecast_results is not None:
                st.session_state.forecast = forecast_results
                
                # äºˆæ¸¬çµæœã®è¡¨ç¤º
                st.subheader("äºˆæ¸¬çµæœ")
                
                # äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
                forecast_df = forecast_results['forecast_df']
                st.dataframe(forecast_df)
                
                # äºˆæ¸¬ã®ãƒ—ãƒ­ãƒƒãƒˆ
                st.subheader("äºˆæ¸¬ã‚°ãƒ©ãƒ•")
                plot_forecast_results(forecast_results, df, target_col, date_col)
                
                # äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                st.markdown("### äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
                create_downloadable_csv(forecast_df, "forecast_data.csv")

def plot_forecast_results(forecast_results, historical_df, target_col, date_col):
    """äºˆæ¸¬çµæœã®ãƒ—ãƒ­ãƒƒãƒˆ"""
    # äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿
    forecast_df = forecast_results['forecast_df']
    
    # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã®æœ€å¾Œã®éƒ¨åˆ†ï¼ˆã‚°ãƒ©ãƒ•è¡¨ç¤ºç”¨ï¼‰
    hist_periods = min(len(historical_df), 365)  # æœ€å¤§ã§1å¹´åˆ†
    hist_df = historical_df.sort_values(by=date_col).tail(hist_periods)
    
    # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã¨äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆã—ãŸãƒ—ãƒ­ãƒƒãƒˆ
    fig = go.Figure()
    
    # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ 
    fig.add_trace(go.Scatter(
        x=hist_df[date_col],
        y=hist_df[target_col],
        mode='lines',
        name='å®Ÿç¸¾å€¤',
        line=dict(color='blue')
    ))
    
    # äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ 
    fig.add_trace(go.Scatter(
        x=forecast_df['date'],
        y=forecast_df['prediction'],
        mode='lines',
        name='äºˆæ¸¬å€¤',
        line=dict(color='red', dash='dash')
    ))
    
    # ä¿¡é ¼åŒºé–“ã®è¿½åŠ 
    fig.add_trace(go.Scatter(
        x=forecast_df['date'],
        y=forecast_df['upper_bound'],
        mode='lines',
        name='ä¸Šé™',
        line=dict(width=0),
        showlegend=False
    ))
    
    fig.add_trace(go.Scatter(
        x=forecast_df['date'],
        y=forecast_df['lower_bound'],
        mode='lines',
        fill='tonexty',
        fillcolor='rgba(255, 0, 0, 0.1)',
        name='95%ä¿¡é ¼åŒºé–“',
        line=dict(width=0)
    ))
    
    # ãƒ—ãƒ­ãƒƒãƒˆã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­å®š
    fig.update_layout(
        title='äºˆæ¸¬çµæœ',
        xaxis_title='æ—¥ä»˜',
        yaxis_title=target_col,
        hovermode='x unified',
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        )
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # å­£ç¯€æ€§ã®åˆ†è§£ã‚’è¡¨ç¤º (Prophetãƒ¢ãƒ‡ãƒ«ã®å ´åˆ)
    if 'components_df' in forecast_results:
        st.subheader("æ™‚ç³»åˆ—ã®åˆ†è§£")
        components_df = forecast_results['components_df']
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰ã®ãƒ—ãƒ­ãƒƒãƒˆ
        fig = px.line(
            components_df, 
            x='ds', 
            y='trend',
            title='ãƒˆãƒ¬ãƒ³ãƒ‰æˆåˆ†'
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # å­£ç¯€æ€§ã®ãƒ—ãƒ­ãƒƒãƒˆ
        seasonality_components = [col for col in components_df.columns if any(s in col for s in ['yearly', 'weekly', 'daily'])]
        
        for component in seasonality_components:
            fig = px.line(
                components_df, 
                x='ds', 
                y=component,
                title=f'{component} å­£ç¯€æ€§'
            )
            st.plotly_chart(fig, use_container_width=True)

def plot_evaluation(evaluation_results):
    """ãƒ¢ãƒ‡ãƒ«è©•ä¾¡çµæœã®ãƒ—ãƒ­ãƒƒãƒˆ"""
    y_true = evaluation_results['y_true']
    y_pred = evaluation_results['y_pred']
    dates = evaluation_results['dates']
    
    # å®Ÿæ¸¬å€¤ã¨äºˆæ¸¬å€¤ã®ãƒ—ãƒ­ãƒƒãƒˆ
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=dates,
        y=y_true,
        mode='lines',
        name='å®Ÿæ¸¬å€¤'
    ))
    
    fig.add_trace(go.Scatter(
        x=dates,
        y=y_pred,
        mode='lines',
        name='äºˆæ¸¬å€¤'
    ))
    
    fig.update_layout(
        title='å®Ÿæ¸¬å€¤ vs äºˆæ¸¬å€¤',
        xaxis_title='æ—¥ä»˜',
        yaxis_title='å€¤',
        hovermode='x unified'
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ
    residuals = y_true - y_pred
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=dates,
        y=residuals,
        mode='markers',
        name='æ®‹å·®',
        marker=dict(color='red')
    ))
    
    fig.add_trace(go.Scatter(
        x=[dates.min(), dates.max()],
        y=[0, 0],
        mode='lines',
        name='ã‚¼ãƒ­ãƒ©ã‚¤ãƒ³',
        line=dict(color='black', dash='dash')
    ))
    
    fig.update_layout(
        title='æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ',
        xaxis_title='æ—¥ä»˜',
        yaxis_title='æ®‹å·®',
        hovermode='x unified'
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # å®Ÿæ¸¬å€¤ã¨äºˆæ¸¬å€¤ã®æ•£å¸ƒå›³
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=y_true,
        y=y_pred,
        mode='markers',
        name='å®Ÿæ¸¬å€¤ vs äºˆæ¸¬å€¤',
        marker=dict(color='blue')
    ))
    
    # 45åº¦ç·šï¼ˆç†æƒ³çš„ãªäºˆæ¸¬ãƒ©ã‚¤ãƒ³ï¼‰
    min_val = min(min(y_true), min(y_pred))
    max_val = max(max(y_true), max(y_pred))
    
    fig.add_trace(go.Scatter(
        x=[min_val, max_val],
        y=[min_val, max_val],
        mode='lines',
        name='ç†æƒ³ãƒ©ã‚¤ãƒ³',
        line=dict(color='red', dash='dash')
    ))
    
    fig.update_layout(
        title='å®Ÿæ¸¬å€¤ vs äºˆæ¸¬å€¤ã®æ•£å¸ƒå›³',
        xaxis_title='å®Ÿæ¸¬å€¤',
        yaxis_title='äºˆæ¸¬å€¤',
        hovermode='closest'
    )
    
    st.plotly_chart(fig, use_container_width=True)

# ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–¢æ•°
def train_model(df, target_col, date_col, model_type, params, test_size=0.2):
    """ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹é–¢æ•°"""
    try:
        # ãƒ‡ãƒ¼ã‚¿ã‚’æ™‚ç³»åˆ—é †ã«ã‚½ãƒ¼ãƒˆ
        df = df.sort_values(by=date_col)
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
        train_size = int(len(df) * (1 - test_size))
        train_df = df.iloc[:train_size]
        test_df = df.iloc[train_size:]
        
        # è¿”å´ã™ã‚‹ãƒ¢ãƒ‡ãƒ«æƒ…å ±
        model_info = {
            'model': None,
            'model_type': model_type,
            'train_df': train_df,
            'test_df': test_df,
            'params': params,
            'scaler': None
        }
        
        # ãƒ¢ãƒ‡ãƒ«åˆ¥ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å‡¦ç†
        if model_type == 'ARIMA':
            from statsmodels.tsa.arima.model import ARIMA
            
            # ARIMAãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
            model = ARIMA(
                train_df[target_col], 
                order=(params['p'], params['d'], params['q'])
            )
            fitted_model = model.fit()
            model_info['model'] = fitted_model
        
        elif model_type == 'SARIMA':
            from statsmodels.tsa.statespace.sarimax import SARIMAX
            
            # SARIMAXãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
            model = SARIMAX(
                train_df[target_col],
                order=(params['p'], params['d'], params['q']),
                seasonal_order=(params['P'], params['D'], params['Q'], params['m'])
            )
            fitted_model = model.fit(disp=False)
            model_info['model'] = fitted_model
        
        elif model_type == 'Prophet':
            from prophet import Prophet
            
            # Prophetã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å½¢å¼ã«å¤‰æ›
            prophet_df = pd.DataFrame({
                'ds': train_df[date_col],
                'y': train_df[target_col]
            })
            
            # Prophetãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
            model = Prophet(
                yearly_seasonality=params.get('yearly_seasonality', 'auto'),
                weekly_seasonality=params.get('weekly_seasonality', 'auto'),
                daily_seasonality=params.get('daily_seasonality', 'auto'),
                seasonality_mode=params.get('seasonality_mode', 'additive')
            )
            
            # ä¼‘æ—¥ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°è¿½åŠ 
            if 'holidays' in params:
                model.add_country_holidays(country_name=params['holidays'])
            
            # è¿½åŠ ã®å­£ç¯€æ€§ãŒã‚ã‚Œã°è¿½åŠ 
            if 'add_seasonality' in params:
                for s in params['add_seasonality']:
                    model.add_seasonality(**s)
            
            # ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
            model.fit(prophet_df)
            model_info['model'] = model
        
        elif model_type == 'Random Forest':
            from sklearn.ensemble import RandomForestRegressor
            from sklearn.preprocessing import StandardScaler
            
            # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®æº–å‚™
            X_cols = [col for col in train_df.columns if col != target_col and col != date_col]
            
            if not X_cols:
                # æ™‚é–“ãƒ™ãƒ¼ã‚¹ã®ç‰¹å¾´é‡ã‚’è‡ªå‹•è¿½åŠ 
                for df_part in [train_df, test_df]:
                    df_part['year'] = df_part[date_col].dt.year
                    df_part['month'] = df_part[date_col].dt.month
                    df_part['day'] = df_part[date_col].dt.day
                    df_part['dayofweek'] = df_part[date_col].dt.dayofweek
                    df_part['quarter'] = df_part[date_col].dt.quarter
                
                X_cols = ['year', 'month', 'day', 'dayofweek', 'quarter']
            
            X_train = train_df[X_cols]
            y_train = train_df[target_col]
            
            # ç‰¹å¾´é‡ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            
            # ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
            model = RandomForestRegressor(
                n_estimators=params.get('n_estimators', 100),
                max_depth=params.get('max_depth', None),
                random_state=42
            )
            
            model.fit(X_train_scaled, y_train)
            
            model_info['model'] = model
            model_info['scaler'] = scaler
            model_info['feature_cols'] = X_cols
        
        return model_info
    
    except Exception as e:
        st.error(f"ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return None

# ãƒ¢ãƒ‡ãƒ«è©•ä¾¡é–¢æ•°
def evaluate_model(model_info, df, target_col, date_col, model_type):
    """ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã™ã‚‹é–¢æ•°"""
    try:
        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
        import numpy as np
        
        test_df = model_info['test_df']
        
        # ãƒ¢ãƒ‡ãƒ«åˆ¥ã®äºˆæ¸¬å‡¦ç†
        if model_type in ['ARIMA', 'SARIMA']:
            # äºˆæ¸¬ã®é–‹å§‹ã¨çµ‚äº†ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            start_idx = len(model_info['train_df'])
            end_idx = start_idx + len(test_df) - 1
            
            # äºˆæ¸¬ã®å®Ÿè¡Œ
            predictions = model_info['model'].predict(start=start_idx, end=end_idx)
            
        elif model_type == 'Prophet':
            # äºˆæ¸¬ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ä½œæˆ
            future = pd.DataFrame({'ds': test_df[date_col]})
            
            # äºˆæ¸¬ã®å®Ÿè¡Œ
            forecast = model_info['model'].predict(future)
            predictions = forecast['yhat'].values
            
        elif model_type == 'Random Forest':
            # ç‰¹å¾´é‡ã®æŠ½å‡ºã¨ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
            X_test = test_df[model_info['feature_cols']]
            X_test_scaled = model_info['scaler'].transform(X_test)
            
            # äºˆæ¸¬ã®å®Ÿè¡Œ
            predictions = model_info['model'].predict(X_test_scaled)
        
        # å®Ÿæ¸¬å€¤
        y_true = test_df[target_col].values
        
        # è©•ä¾¡æŒ‡æ¨™ã®è¨ˆç®—
        mse = mean_squared_error(y_true, predictions)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_true, predictions)
        r2 = r2_score(y_true, predictions)
        
        # MAPE (Mean Absolute Percentage Error)ã®è¨ˆç®—
        mask = y_true != 0  # ã‚¼ãƒ­é™¤ç®—ã‚’é¿ã‘ã‚‹
        mape = np.mean(np.abs((y_true[mask] - predictions[mask]) / y_true[mask])) * 100
        
        # è©•ä¾¡çµæœã®è¿”å´
        return {
            'rmse': rmse,
            'mae': mae,
            'mape': mape,
            'r2': r2,
            'y_true': y_true,
            'y_pred': predictions,
            'dates': test_df[date_col].values
        }
    
    except Exception as e:
        st.error(f"ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return None

# äºˆæ¸¬ç”Ÿæˆé–¢æ•°
def generate_forecast(model_info, df, target_col, date_col, model_type, forecast_periods, confidence_level=0.95):
    """å°†æ¥äºˆæ¸¬ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°"""
    try:
        # æœ€å¾Œã®æ—¥ä»˜ã‚’å–å¾—
        last_date = df[date_col].max()
        
        # ãƒ‡ãƒ¼ã‚¿é »åº¦ã®å–å¾—
        freq = st.session_state.data_frequency
        
        # é »åº¦ã«åŸºã¥ãæ—¥ä»˜ã®ã‚ªãƒ•ã‚»ãƒƒãƒˆãƒãƒƒãƒ—
        freq_map = {
            'hourly': 'H',
            'daily': 'D',
            'weekly': 'W',
            'monthly': 'M',
            'quarterly': 'Q',
            'yearly': 'Y'
        }
        
        offset = freq_map.get(freq, 'D')
        
        # å°†æ¥æ—¥ä»˜ã®ç”Ÿæˆ
        future_dates = pd.date_range(
            start=last_date + pd.Timedelta(days=1), 
            periods=forecast_periods,
            freq=offset
        )
        
        # ãƒ¢ãƒ‡ãƒ«åˆ¥ã®äºˆæ¸¬å‡¦ç†
        if model_type in ['ARIMA', 'SARIMA']:
            # äºˆæ¸¬ã¨ä¿¡é ¼åŒºé–“
            forecast_result = model_info['model'].get_forecast(steps=forecast_periods)
            predictions = forecast_result.predicted_mean
            
            # ä¿¡é ¼åŒºé–“
            conf_int = forecast_result.conf_int(alpha=1-confidence_level)
            lower_bounds = conf_int.iloc[:, 0]
            upper_bounds = conf_int.iloc[:, 1]
            
            # äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ä½œæˆ
            forecast_df = pd.DataFrame({
                'date': future_dates,
                'prediction': predictions.values,
                'lower_bound': lower_bounds.values,
                'upper_bound': upper_bounds.values
            })
            
            result = {'forecast_df': forecast_df}
            
        elif model_type == 'Prophet':
            # äºˆæ¸¬ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ä½œæˆ
            future = pd.DataFrame({'ds': pd.concat([df[date_col], pd.Series(future_dates)])})
            
            # äºˆæ¸¬ã®å®Ÿè¡Œ
            forecast = model_info['model'].predict(future)
            
            # äºˆæ¸¬æœŸé–“ã®ã¿ã‚’æŠ½å‡º
            forecast_result = forecast.tail(forecast_periods)
            
            # äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ä½œæˆ
            forecast_df = pd.DataFrame({
                'date': forecast_result['ds'],
                'prediction': forecast_result['yhat'],
                'lower_bound': forecast_result['yhat_lower'],
                'upper_bound': forecast_result['yhat_upper']
            })
            
            # æˆåˆ†åˆ†è§£ã‚’å«ã‚€çµæœ
            result = {
                'forecast_df': forecast_df,
                'components_df': forecast_result[['ds', 'trend'] + [col for col in forecast_result.columns if 'seasonality' in col]]
            }
            
        elif model_type == 'Random Forest':
            # å°†æ¥ã®ç‰¹å¾´é‡ã‚’ç”Ÿæˆ
            future_df = pd.DataFrame({'date': future_dates})
            
            # æ™‚é–“ãƒ™ãƒ¼ã‚¹ã®ç‰¹å¾´é‡ã‚’è¿½åŠ 
            future_df['year'] = future_df['date'].dt.year
            future_df['month'] = future_df['date'].dt.month
            future_df['day'] = future_df['date'].dt.day
            future_df['dayofweek'] = future_df['date'].dt.dayofweek
            future_df['quarter'] = future_df['date'].dt.quarter
            
            # ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡ã ã‘ã‚’æŠ½å‡º
            X_future = future_df[model_info['feature_cols']]
            
            # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
            X_future_scaled = model_info['scaler'].transform(X_future)
            
            # äºˆæ¸¬ã®å®Ÿè¡Œ
            predictions = model_info['model'].predict(X_future_scaled)
            
            # ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã®å ´åˆã€äºˆæ¸¬åŒºé–“ã‚’æ¨å®š
            # (å˜ç´”ãªè¿‘ä¼¼ã¨ã—ã¦æ¨™æº–åå·®ã‚’ä½¿ç”¨)
            from scipy import stats
            
            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ®‹å·®ã‹ã‚‰æ¨™æº–åå·®ã‚’è¨ˆç®—
            test_predictions = model_info['model'].predict(
                model_info['scaler'].transform(model_info['test_df'][model_info['feature_cols']])
            )
            residuals = model_info['test_df'][target_col].values - test_predictions
            std_dev = residuals.std()
            
            # ä¿¡é ¼åŒºé–“ã®è¨ˆç®—ï¼ˆæ­£è¦åˆ†å¸ƒã‚’ä»®å®šï¼‰
            z_score = stats.norm.ppf((1 + confidence_level) / 2)
            margin = z_score * std_dev
            
            # äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ä½œæˆ
            forecast_df = pd.DataFrame({
                'date': future_dates,
                'prediction': predictions,
                'lower_bound': predictions - margin,
                'upper_bound': predictions + margin
            })
            
            result = {'forecast_df': forecast_df}
        
        # å¤‰æ›æƒ…å ±ãŒã‚ã‚‹å ´åˆã¯å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ã«æˆ»ã™
        if st.session_state.transform_info is not None:
            result['forecast_df']['prediction'] = inverse_transform(
                result['forecast_df']['prediction'],
                st.session_state.transform_info
            )
            result['forecast_df']['lower_bound'] = inverse_transform(
                result['forecast_df']['lower_bound'],
                st.session_state.transform_info
            )
            result['forecast_df']['upper_bound'] = inverse_transform(
                result['forecast_df']['upper_bound'],
                st.session_state.transform_info
            )
        
        return result
    
    except Exception as e:
        st.error(f"äºˆæ¸¬ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return None

# ãƒ¡ã‚¤ãƒ³é–¢æ•°
def main():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ"""
    # ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³è¡¨ç¤º
    navigation()
    
    # ç¾åœ¨ã®ãƒšãƒ¼ã‚¸ã«å¿œã˜ã¦è¡¨ç¤º
    if st.session_state.page == 'upload':
        show_upload_page()
    elif st.session_state.page == 'eda':
        show_eda_page()
    elif st.session_state.page == 'training':
        show_training_page()
    elif st.session_state.page == 'forecast':
        show_forecast_page()

# ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰é–¢æ•°
def load_data(file):
    """ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    try:
        df = load_cached_data(file)
        return df
    except Exception as e:
        show_error(f"ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
if __name__ == "__main__":
    main()